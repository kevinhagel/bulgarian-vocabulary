---
phase: 02-llm-integration
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - src/main/java/com/vocab/bulgarian/llm/service/LemmaDetectionService.java
  - src/main/java/com/vocab/bulgarian/llm/service/InflectionGenerationService.java
  - src/main/java/com/vocab/bulgarian/llm/service/MetadataGenerationService.java
  - src/main/java/com/vocab/bulgarian/llm/validation/LlmOutputValidator.java
  - src/main/java/com/vocab/bulgarian/llm/validation/LlmValidationException.java
  - src/main/java/com/vocab/bulgarian/llm/service/LlmOrchestrationService.java
autonomous: true

must_haves:
  truths:
    - "LLM can detect lemma from any Bulgarian word form via LemmaDetectionService"
    - "LLM can generate all inflections for a lemma via InflectionGenerationService"
    - "LLM can generate part of speech, category, and difficulty via MetadataGenerationService"
    - "LLM responses are cached to avoid redundant API calls"
    - "LLM calls execute asynchronously without blocking request threads"
    - "Circuit breaker activates when Ollama is unavailable"
    - "LLM outputs are validated for empty fields, Cyrillic content, and domain rules"
    - "Orchestration service composes async LLM calls and stages results for user review"
  artifacts:
    - path: "src/main/java/com/vocab/bulgarian/llm/service/LemmaDetectionService.java"
      provides: "Async cached circuit-broken lemma detection from word forms"
      contains: "detectLemma"
    - path: "src/main/java/com/vocab/bulgarian/llm/service/InflectionGenerationService.java"
      provides: "Async cached circuit-broken inflection generation"
      contains: "generateInflections"
    - path: "src/main/java/com/vocab/bulgarian/llm/service/MetadataGenerationService.java"
      provides: "Async cached circuit-broken metadata generation"
      contains: "generateMetadata"
    - path: "src/main/java/com/vocab/bulgarian/llm/validation/LlmOutputValidator.java"
      provides: "Validation for LLM outputs (schema + Bulgarian morphology rules)"
      contains: "validateInflectionSet"
    - path: "src/main/java/com/vocab/bulgarian/llm/validation/LlmValidationException.java"
      provides: "Custom exception for LLM validation failures"
      contains: "LlmValidationException"
    - path: "src/main/java/com/vocab/bulgarian/llm/service/LlmOrchestrationService.java"
      provides: "Composes all LLM calls for new vocabulary entry processing"
      contains: "processNewWord"
  key_links:
    - from: "src/main/java/com/vocab/bulgarian/llm/service/LemmaDetectionService.java"
      to: "ChatClient"
      via: "Injected ChatClient for Ollama API calls"
      pattern: "chatClient\\.prompt"
    - from: "src/main/java/com/vocab/bulgarian/llm/service/LemmaDetectionService.java"
      to: "Caffeine cache"
      via: "@Cacheable annotation"
      pattern: "@Cacheable.*lemmaDetection"
    - from: "src/main/java/com/vocab/bulgarian/llm/service/LemmaDetectionService.java"
      to: "Resilience4j circuit breaker"
      via: "@CircuitBreaker annotation"
      pattern: "@CircuitBreaker.*ollama"
    - from: "src/main/java/com/vocab/bulgarian/llm/service/LlmOrchestrationService.java"
      to: "All three LLM services"
      via: "Constructor injection, CompletableFuture composition"
      pattern: "thenCompose|thenCombine"
    - from: "src/main/java/com/vocab/bulgarian/llm/validation/LlmOutputValidator.java"
      to: "LLM service classes"
      via: "Injected into services, called after BeanOutputConverter"
      pattern: "validator\\.validate"
---

<objective>
Implement the three LLM service classes (lemma detection, inflection generation, metadata generation), LLM output validator, and orchestration service that composes async calls for new vocabulary entries.

Purpose: Deliver the core LLM functionality -- Bulgarian word processing via Ollama with async execution, caching, circuit breaker protection, validation, and a composition layer that stages results for user review (ReviewStatus.PENDING).
Output: Complete LLM service layer ready for integration with vocabulary CRUD in Phase 4.
</objective>

<execution_context>
@/Users/kevin/.claude/get-shit-done/workflows/execute-plan.md
@/Users/kevin/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-llm-integration/02-RESEARCH.md
@.planning/phases/02-llm-integration/02-01-SUMMARY.md

# Configuration created by Plan 01
@src/main/java/com/vocab/bulgarian/llm/config/AsyncConfig.java
@src/main/java/com/vocab/bulgarian/llm/config/CacheConfig.java
@src/main/java/com/vocab/bulgarian/llm/config/LlmConfig.java

# DTOs created by Plan 01
@src/main/java/com/vocab/bulgarian/llm/dto/LemmaDetectionResponse.java
@src/main/java/com/vocab/bulgarian/llm/dto/InflectionSet.java
@src/main/java/com/vocab/bulgarian/llm/dto/LemmaMetadata.java

# Existing domain model
@src/main/java/com/vocab/bulgarian/domain/Lemma.java
@src/main/java/com/vocab/bulgarian/domain/Inflection.java
@src/main/java/com/vocab/bulgarian/domain/enums/PartOfSpeech.java
@src/main/java/com/vocab/bulgarian/domain/enums/DifficultyLevel.java
@src/main/java/com/vocab/bulgarian/domain/enums/ReviewStatus.java
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create LLM output validator and exception class</name>
  <files>
    src/main/java/com/vocab/bulgarian/llm/validation/LlmValidationException.java
    src/main/java/com/vocab/bulgarian/llm/validation/LlmOutputValidator.java
  </files>
  <action>
**A) Create LlmValidationException.java** in `com.vocab.bulgarian.llm.validation`:
- Extend `RuntimeException`
- Constructor taking `String message`
- Constructor taking `String message, Throwable cause`

**B) Create LlmOutputValidator.java** in `com.vocab.bulgarian.llm.validation`:
- `@Component`
- Inject `jakarta.validation.Validator` for Bean Validation
- Three public methods:

**`validateLemmaDetection(LemmaDetectionResponse response)`:**
- Reject if response is null
- Reject if `detectionFailed` is true (this is expected for fallbacks -- don't validate further)
- Run Jakarta Bean Validation (`validator.validate(response)`) -- throw `LlmValidationException` with violations if any
- Reject if `lemma` is blank or contains no Cyrillic characters (regex: `.*[а-яА-Я].*`)
- Reject if `lemma` length > 100 (schema limit)

**`validateInflectionSet(InflectionSet set)`:**
- Reject if null
- Run Jakarta Bean Validation
- Reject if `inflections` list is empty
- Reject if any inflection `text` is blank or contains no Cyrillic characters
- Check for duplicate inflection texts (using HashSet)
- Minimum inflection count by part of speech:
  - VERB: at least 6 inflections (6 person/number forms for present tense minimum)
  - NOUN: at least 2 inflections (singular, plural minimum)
  - ADJECTIVE: at least 3 inflections (masculine, feminine, neuter minimum)
  - Other: at least 1 inflection

**`validateLemmaMetadata(LemmaMetadata metadata)`:**
- Reject if null
- Run Jakarta Bean Validation
- Reject if `partOfSpeech` does not match any `PartOfSpeech` enum value (case-insensitive comparison)
- Reject if `difficultyLevel` does not match any `DifficultyLevel` enum value (case-insensitive comparison)
- Category is optional (can be null/blank)

All rejection methods throw `LlmValidationException` with descriptive message.
Add private helper: `containsCyrillic(String text)` using regex `.*[а-яА-Я].*`.
  </action>
  <verify>Run `cd /Users/kevin/projects/bulgarian-vocabulary && ./mvnw compile -q` to confirm both classes compile.</verify>
  <done>LlmValidationException and LlmOutputValidator compile, validator has 3 validation methods covering schema validation, Cyrillic checks, duplicate detection, and Bulgarian morphology minimum counts.</done>
</task>

<task type="auto">
  <name>Task 2: Create three LLM service classes with async, caching, and circuit breaker</name>
  <files>
    src/main/java/com/vocab/bulgarian/llm/service/LemmaDetectionService.java
    src/main/java/com/vocab/bulgarian/llm/service/InflectionGenerationService.java
    src/main/java/com/vocab/bulgarian/llm/service/MetadataGenerationService.java
  </files>
  <action>
**IMPORTANT DESIGN NOTE (from Research pitfall #2):** Do NOT put `@Cacheable` on methods returning `CompletableFuture` -- it caches the future wrapper, not the result. Instead, use a two-layer approach: a synchronous `@Cacheable` + `@CircuitBreaker` method that does the actual LLM call, and a separate `@Async` public method that wraps it in CompletableFuture.

**A) LemmaDetectionService.java** in `com.vocab.bulgarian.llm.service`:
- `@Service`
- Inject `ChatClient` and `LlmOutputValidator`
- Public async method: `CompletableFuture<LemmaDetectionResponse> detectLemmaAsync(String wordForm)`
  - `@Async("llmTaskExecutor")`
  - Calls the synchronous method and wraps result in `CompletableFuture.completedFuture()`
- Package-private synchronous method: `LemmaDetectionResponse detectLemma(String wordForm)`
  - `@Cacheable(value = "lemmaDetection", key = "#wordForm.trim().toLowerCase()")`
  - `@CircuitBreaker(name = "ollama", fallbackMethod = "detectLemmaFallback")`
  - Normalize input: `wordForm.trim().toLowerCase()`
  - Build prompt using ChatClient fluent API:
    ```
    Given the Bulgarian word "{wordForm}", identify its lemma (dictionary form).
    For verbs, the lemma is the 1st person singular present tense form.
    For nouns, the lemma is the singular indefinite form.
    For adjectives, the lemma is the masculine singular indefinite form.

    Respond in JSON format: {format}
    ```
  - Use `.call().entity(LemmaDetectionResponse.class)` for structured output
  - Call `validator.validateLemmaDetection(response)` before returning
- Fallback method: `LemmaDetectionResponse detectLemmaFallback(String wordForm, Exception ex)`
  - Log warning with exception message
  - Return `LemmaDetectionResponse.failed(wordForm)`

**B) InflectionGenerationService.java** in `com.vocab.bulgarian.llm.service`:
- `@Service`
- Inject `ChatClient` and `LlmOutputValidator`
- Public async method: `CompletableFuture<InflectionSet> generateInflectionsAsync(String lemma, String partOfSpeech)`
  - `@Async("llmTaskExecutor")`
  - Calls synchronous method, wraps in CompletableFuture
- Package-private synchronous method: `InflectionSet generateInflections(String lemma, String partOfSpeech)`
  - `@Cacheable(value = "inflectionGeneration", key = "#lemma.trim().toLowerCase() + ':' + #partOfSpeech")`
  - `@CircuitBreaker(name = "ollama", fallbackMethod = "generateInflectionsFallback")`
  - Build prompt:
    ```
    Generate ALL inflections for the Bulgarian {partOfSpeech} "{lemma}".

    For verbs, include all persons (1st, 2nd, 3rd) and numbers (singular, plural)
    for present tense, past aorist, past imperfect, and imperative mood.
    Include the grammatical tags for each form (e.g., "1sg.pres", "3pl.past.aor").

    For nouns, include singular and plural forms, with and without the definite article.
    Include grammatical tags (e.g., "sg.indef", "sg.def", "pl.indef", "pl.def").

    For adjectives, include masculine, feminine, neuter, and plural forms,
    with and without the definite article.

    Respond in JSON format: {format}
    ```
  - Use `.call().entity(InflectionSet.class)` for structured output
  - Call `validator.validateInflectionSet(response)` before returning
- Fallback: return null (caller handles null as generation failure)

**C) MetadataGenerationService.java** in `com.vocab.bulgarian.llm.service`:
- `@Service`
- Inject `ChatClient` and `LlmOutputValidator`
- Public async method: `CompletableFuture<LemmaMetadata> generateMetadataAsync(String lemma)`
  - `@Async("llmTaskExecutor")`
  - Calls synchronous method, wraps in CompletableFuture
- Package-private synchronous method: `LemmaMetadata generateMetadata(String lemma)`
  - `@Cacheable(value = "metadataGeneration", key = "#lemma.trim().toLowerCase()")`
  - `@CircuitBreaker(name = "ollama", fallbackMethod = "generateMetadataFallback")`
  - Build prompt:
    ```
    For the Bulgarian word "{lemma}", determine:
    1. Part of speech (one of: NOUN, VERB, ADJECTIVE, ADVERB, PRONOUN, PREPOSITION, CONJUNCTION, NUMERAL, INTERJECTION, PARTICLE, INTERROGATIVE)
    2. Topic category (e.g., "food", "travel", "emotions", "daily life", "academic")
    3. Difficulty level (one of: BEGINNER, INTERMEDIATE, ADVANCED)

    BEGINNER: common everyday words (greetings, numbers, family, food basics)
    INTERMEDIATE: general conversation words (opinions, descriptions, activities)
    ADVANCED: specialized or abstract vocabulary (politics, philosophy, technical)

    Respond in JSON format: {format}
    ```
  - Use `.call().entity(LemmaMetadata.class)` for structured output
  - Call `validator.validateLemmaMetadata(response)` before returning
- Fallback: return null (caller handles null as generation failure)

All services use SLF4J logging (`@Slf4j` or `LoggerFactory`). Log at DEBUG level for prompt/response, WARN for fallback activation, ERROR for validation failures.
  </action>
  <verify>Run `cd /Users/kevin/projects/bulgarian-vocabulary && ./mvnw compile -q` to confirm all 3 services compile. Run `grep -rn "@Cacheable" src/main/java/com/vocab/bulgarian/llm/service/` to confirm caching is on synchronous methods (not on methods returning CompletableFuture). Run `grep -rn "@CircuitBreaker" src/main/java/com/vocab/bulgarian/llm/service/` to confirm circuit breaker annotations.</verify>
  <done>Three LLM services compile: LemmaDetectionService detects lemmas from word forms, InflectionGenerationService generates all inflections, MetadataGenerationService determines POS/category/difficulty. All use @Async for non-blocking, @Cacheable on synchronous methods for correct caching, and @CircuitBreaker with fallback methods.</done>
</task>

<task type="auto">
  <name>Task 3: Create LLM orchestration service for vocabulary entry processing</name>
  <files>
    src/main/java/com/vocab/bulgarian/llm/service/LlmOrchestrationService.java
  </files>
  <action>
Create `LlmOrchestrationService.java` in `com.vocab.bulgarian.llm.service`:

- `@Service`
- Inject all three LLM services: `LemmaDetectionService`, `InflectionGenerationService`, `MetadataGenerationService`

**Main public method: `CompletableFuture<LlmProcessingResult> processNewWord(String wordForm)`**

This method orchestrates the full LLM pipeline for a new vocabulary entry:

1. **Step 1:** Call `lemmaDetectionService.detectLemmaAsync(wordForm)` to get the lemma
2. **Step 2:** When lemma is detected, fan out two parallel calls:
   - `inflectionGenerationService.generateInflectionsAsync(lemma, partOfSpeech)`
   - `metadataGenerationService.generateMetadataAsync(lemma)`
3. **Step 3:** Combine all three results into `LlmProcessingResult`

Use `CompletableFuture.thenCompose()` for step 1->2 dependency, and `thenCombine()` for step 2 parallel execution.

Handle failures gracefully:
- If lemma detection fails (`detectionFailed == true`): return result with failed status, original wordForm preserved
- If inflection generation returns null: result has empty inflections list, not a full failure
- If metadata generation returns null: result has null metadata, not a full failure

**Create inner/nested record or separate class `LlmProcessingResult`:**

Define as a record in the same file or in `com.vocab.bulgarian.llm.dto.LlmProcessingResult`:
```java
public record LlmProcessingResult(
    String originalWordForm,
    LemmaDetectionResponse lemmaDetection,
    InflectionSet inflections,          // nullable -- generation may fail
    LemmaMetadata metadata,             // nullable -- generation may fail
    boolean fullySuccessful,            // true only if all 3 succeeded
    List<String> warnings               // partial failure messages
) {}
```

Place `LlmProcessingResult` in `com.vocab.bulgarian.llm.dto` package (separate file).

The orchestration service logs:
- INFO: "Processing new word: {wordForm}"
- INFO: "Lemma detected: {lemma} for word form: {wordForm}"
- WARN: for any partial failures (null inflections, null metadata)
- INFO: "Processing complete for {wordForm}: fullySuccessful={result}"

This service does NOT persist to database. It produces the DTO that Phase 4's vocabulary service will use to create Lemma/Inflection entities and set `reviewStatus = ReviewStatus.PENDING` (LLM-06 requirement -- user reviews before saving).
  </action>
  <verify>Run `cd /Users/kevin/projects/bulgarian-vocabulary && ./mvnw compile -q` to confirm orchestration service and LlmProcessingResult compile. Run `grep -rn "thenCompose\|thenCombine" src/main/java/com/vocab/bulgarian/llm/service/LlmOrchestrationService.java` to confirm async composition pattern.</verify>
  <done>LlmOrchestrationService compiles, composes three async LLM calls (detect lemma -> fan out to inflections + metadata in parallel), returns LlmProcessingResult with partial failure handling and warnings list. Ready for Phase 4 vocabulary service integration.</done>
</task>

</tasks>

<verification>
1. `./mvnw compile -q` compiles without errors
2. `find src/main/java/com/vocab/bulgarian/llm -type f -name "*.java" | sort` shows all files:
   - 3 config files (from Plan 01)
   - 4 dto files (3 from Plan 01 + LlmProcessingResult)
   - 3 service files
   - 2 validation files
   Total: 12 Java files in the llm package
3. `grep -rn "@Cacheable" src/main/java/com/vocab/bulgarian/llm/` shows 3 cache annotations (one per service)
4. `grep -rn "@CircuitBreaker" src/main/java/com/vocab/bulgarian/llm/` shows 3 circuit breaker annotations
5. `grep -rn "@Async" src/main/java/com/vocab/bulgarian/llm/` shows 3+ async annotations
6. `grep -rn "thenCompose\|thenCombine" src/main/java/com/vocab/bulgarian/llm/` shows CompletableFuture composition
7. `grep -rn "containsCyrillic\|Cyrillic" src/main/java/com/vocab/bulgarian/llm/validation/` confirms Cyrillic validation
</verification>

<success_criteria>
- LemmaDetectionService: async, cached, circuit-broken lemma detection with Bulgarian-specific prompts
- InflectionGenerationService: async, cached, circuit-broken inflection generation with morphology-aware prompts
- MetadataGenerationService: async, cached, circuit-broken metadata generation (POS, category, difficulty)
- LlmOutputValidator: validates schema compliance, Cyrillic characters, duplicate inflections, morphology minimums
- LlmOrchestrationService: composes 3 async calls (detect -> fan out inflections + metadata), returns LlmProcessingResult
- Cache on synchronous methods (not CompletableFuture wrappers) -- avoids pitfall #2
- All services have circuit breaker fallbacks that return graceful failures
- Application compiles without errors
</success_criteria>

<output>
After completion, create `.planning/phases/02-llm-integration/02-02-SUMMARY.md`
</output>
