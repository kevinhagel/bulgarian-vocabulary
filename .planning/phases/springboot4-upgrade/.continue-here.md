---
phase: springboot4-upgrade
task: 0
total_tasks: 5
status: not_started
last_updated: 2026-02-24T10:36:33.466Z
---

<current_state>
Spring Boot upgrade NOT started. Build is stable on 3.4.2. pom.xml was reverted
to last committed working state. Ready to begin a clean upgrade session.
</current_state>

<completed_work>
- Research complete (see .planning/phases/springboot4-upgrade/01-RESEARCH.md)
- Confirmed Spring Boot 4.0.3 is the target (latest stable, released 2026-02-19)
- Identified all breaking changes and version requirements
</completed_work>

<remaining_work>
All tasks remain:

- Task 1: Update pom.xml with all new versions
- Task 2: Fix Spring AI 2.0.0-M2 package changes (OllamaOptions moved)
- Task 3: Fix starter renames and Resilience4j
- Task 4: Build, fix remaining compile errors
- Task 5: Deploy to Docker, verify app starts and LLM pipeline works
</remaining_work>

<decisions_made>
- Spring Boot: 3.4.2 → 4.0.3
- Spring AI BOM: 1.1.0-M3 → 2.0.0-M2 (no GA yet, milestone acceptable)
- Spring Cloud BOM: 2024.0.0 → 2025.1.1 (Oakwood)
- Maven compiler plugin: 3.13.0 → 3.15.0
- Compiler <release>: 21 → 25 (Boot 4 ASM supports Java 25)
- spring-boot-starter-aop → spring-boot-starter-aspectj (renamed in Boot 4)
- resilience4j-spring-boot3 2.2.0 → keep spring-boot3 artifact at 2.3.0 (spring-boot4 not on Maven Central)
- MapStruct: stay on 1.6.2, test after compile, upgrade to 1.7.x if needed
</decisions_made>

<blockers>
- Spring AI 2.0.0-M2: OllamaOptions moved OUT of org.springframework.ai.ollama.api
  → Need to find new package. Check spring-ai-ollama jar or Spring AI 2.0 migration guide.
  Affected files: OllamaConfig.java, LlmConfig.java
- resilience4j-spring-boot4 not on Maven Central (only 2.3.1-SNAPSHOT)
  → Workaround: keep resilience4j-spring-boot3 at 2.3.0, test if it works with Boot 4
</blockers>

<context>
This is a clean, standalone upgrade task. The current session ran out of context
mid-attempt. The build was reverted to working 3.4.2 state before ending.

The main risk is Spring AI 2.x API changes — the LLM pipeline (OllamaConfig,
LlmConfig, the 4 LLM services) all use Spring AI types that may have moved.
Start by finding the correct Spring AI 2.x package names before touching pom.xml.

Deploy workflow (unchanged): mvn package -DskipTests && docker-compose build backend && docker-compose up -d backend
</context>

<next_action>
1. Find new OllamaOptions package in Spring AI 2.0.0-M2:
   mvn dependency:get -Dartifact=org.springframework.ai:spring-ai-ollama:2.0.0-M2
   then: jar tf ~/.m2/repository/org/springframework/ai/spring-ai-ollama/2.0.0-M2/*.jar | grep OllamaOptions
2. Update pom.xml with all new versions
3. Fix compile errors one by one
</next_action>
