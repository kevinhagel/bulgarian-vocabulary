# Session Summary: 2026-02-16

## Session Info
- **Date:** 2026-02-16
- **Duration:** ~4.5 hours
- **Phase:** Phase 5 - Frontend Foundation & Vocabulary UI
- **GSD State:** `.planning/STATE.md`

---

## What We Worked On

Migrated the full development environment to Mac Studio, fixed Cyrillic font rendering, optimized GPU settings for Ollama, and completed Phase 5 frontend work. Discovered a critical LLM latency problem (60-90s per entry) that blocked acceptable UX.

---

## Accomplishments

### ‚úÖ Application Migrated to Mac Studio
- Moved entire development environment to Mac Studio (M4 Max, 32 GPU cores)
- All services running locally: PostgreSQL, Valkey, Ollama, backend, frontend
- No more SSH tunnels needed ‚Äî everything is localhost

### ‚úÖ Git Repository Created
- Initialized git repository with comprehensive .gitignore
- Committed all code (150 files, 24K+ lines)
- Pushed to GitHub: https://github.com/kevinhagel/bulgarian-vocabulary
- Initial commit includes Phases 1‚Äì5 complete

### ‚úÖ Cyrillic Font Rendering Fixed
- **Problem:** Bulgarian text showing as wrong characters (–¥‚Üíg, –±‚Üí6, –∑‚Üí3)
- **Root cause:** System fonts using cursive Cyrillic glyphs
- **Solution:** Switched to Inter / Sofia Sans fonts (Google Fonts) for print-style rendering
- **Result:** Clean, readable Bulgarian text throughout app

### ‚úÖ Backend Fixes
- Fixed Spring Boot Ollama configuration (`OllamaConfig.java`)
- Fixed audio API JSON format (`AudioPlayButton.tsx`)
- Added UTF-8 encoding filter (`EncodingFilter.java`, `WebConfig.java`)
- Fixed duplicate inflection validation (`LlmOutputValidator.java`)
- Increased async request timeout for LLM (30s ‚Üí 120s)

### ‚úÖ GPU Optimization
- Configured Ollama to use all 32 GPU cores (M4 Max)
- Tuned num-ctx, num-gpu, num-thread parameters
- Verified 28GB model loaded in VRAM
- Confirmed Metal 4 GPU acceleration active

### ‚úÖ Phase 5 Complete (4/4 Plans)
- React 19 + Vite 6 + TypeScript ‚úì
- TanStack Query + Zustand state management ‚úì
- Vocabulary list with Cyrillic rendering ‚úì
- Add/Edit/Delete vocabulary ‚úì
- Search and filtering ‚úì
- Audio playback for lemmas ‚úì
- Detail view with inflections table ‚úì
- Mobile responsive ‚úì

---

## Issues Encountered

### ‚ùå LLM Processing Speed (Critical / Deferred)
- **Symptom:** 60‚Äì90 seconds to create each vocabulary entry
- **Root Cause:** Synchronous processing blocks UI; BgGPT (9B model) is slow even on M4 Max
- **Test:** `qwen2.5:7b` was faster (33s) but inaccurate ‚Äî –ø–ª–µ—Ç–µ‚Üí–ø–ª–µ—Ç–µ (wrong lemma)
- **Resolution:** Deferred to Phase 6 ‚Äî background processing pipeline + Google Translate

---

## Phase Status

**Phase 5 ‚Äî Frontend Foundation & Vocabulary UI:** 95% complete (critical UX issue blocking full sign-off)

| Plan | Status | Notes |
|------|--------|-------|
| 05-01 | ‚úì Complete | React scaffolding, API client, AudioPlayer |
| 05-02 | ‚úì Complete | Vocabulary list, search, filters, pagination |
| 05-03 | ‚úì Complete | CRUD forms with validation |
| 05-04 | üü° Partial | VocabularyDetail page exists, UAT blocked by LLM speed |

---

## Current GSD Position

```
Phase:  5 complete ‚Üí 6 ready to plan
Plan:   Phase 6 not started
Status: Paused for background processing redesign
```

**Next action:** Plan Phase 6 ‚Äî background processing pipeline (save immediately + async LLM), Google Translate integration, then flashcard study mode.

---

## Key Decisions Made

| Decision | Rationale |
|----------|-----------|
| All dev on Mac Studio | M4 Max GPU + 32 cores ‚Üí best LLM perf; no network hop |
| Sofia Sans for Cyrillic | Inter/system fonts use cursive glyphs; Sofia Sans is print-style |
| Background processing for Phase 6 | Sync LLM calls (60-90s) are unacceptable UX; must decouple |
| Keep BgGPT over qwen2.5 | Accuracy required for Bulgarian morphology; speed is solvable |

---

## Technical Notes

```bash
# Services running on Mac Studio
docker-compose up -d                          # PostgreSQL, Valkey, pgAdmin
mvn spring-boot:run -Dspring-boot.run.profiles=dev  # Backend on :8080
npm run dev                                   # Frontend on :5173
```

iPhone access worked via `http://192.168.1.10:5173` ‚Äî Vite configured with `host: '0.0.0.0'` and `allowedHosts` list.

---

## Lessons Learned

1. Font rendering for Cyrillic requires explicit font selection (system defaults use cursive glyphs)
2. 9B quantized models too slow for synchronous UX even on M4 Max GPU
3. Background processing is essential for LLM-heavy workflows
4. Bulgarian-specific models (BgGPT) necessary for accurate morphology
5. UAT reveals fundamental design issues that unit tests miss

---

## Hardware Validated
- Mac Studio M4 Max with 32 GPU cores fully functional
- Ollama using GPU acceleration (28GB VRAM)
- Model inference speed limited by model size, not hardware

---

*Session Date: 2026-02-16*
*Duration: ~4.5 hours*
*Status: Phase 5 at 95%, paused for background processing redesign*
*Written by: Claude Code (claude-sonnet-4-5)*
